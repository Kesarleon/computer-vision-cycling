{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo de Detección de Ciclistas\n",
    "\n",
    "Este notebook cubre el proceso completo para entrenar un modelo de CNN para detectar bicicletas en fotogramas de video. El proceso incluye:\n",
    "\n",
    "1.  **Extracción de Fotogramas:** Extraer fotogramas de videos de muestra.\n",
    "2.  **Generación de Archivo de Etiquetas:** Crear un `labels.csv` para que el usuario lo complete.\n",
    "3.  **Carga y Preprocesamiento de Datos:** Cargar los fotogramas y etiquetas, y prepararlos para el entrenamiento.\n",
    "4.  **Construcción y Entrenamiento del Modelo:** Definir y entrenar un modelo de CNN.\n",
    "5.  **Guardado del Modelo:** Guardar el modelo entrenado para su uso en la aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparación de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Preparación de Datos de Entrenamiento (Automatizado)\n",
    "\n",
    "Esta celda automatiza la preparación de datos. Si encuentra videos en `../data`, extraerá fotogramas. Si no, creará imágenes de demostración para asegurar que el notebook se pueda ejecutar de principio a fin sin intervención manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training_data(video_dir='../data', frames_dir='../data/frames', labels_csv='../data/labels.csv'):\n",
    "    # 1. Preparar el directorio de fotogramas\n",
    "    if not os.path.exists(frames_dir):\n",
    "        os.makedirs(frames_dir)\n",
    "    else:\n",
    "        shutil.rmtree(frames_dir)\n",
    "        os.makedirs(frames_dir)\n",
    "    \n",
    "    # 2. Extraer fotogramas si existen videos\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi'))]\n",
    "    frame_count = 0\n",
    "    if video_files:\n",
    "        print(f\"Videos encontrados: {video_files}. Extrayendo fotogramas...\")\n",
    "        for video_file in video_files:\n",
    "            video_path = os.path.join(video_dir, video_file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            if fps == 0: continue\n",
    "            frame_interval = int(fps) # Un fotograma por segundo\n",
    "            while cap.isOpened():\n",
    "                frame_id = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                ret, frame = cap.read()\n",
    "                if not ret: break\n",
    "                if frame_id % frame_interval == 0:\n",
    "                    cv2.imwrite(os.path.join(frames_dir, f\"frame_{frame_count:04d}.jpg\"), frame)\n",
    "                    frame_count += 1\n",
    "            cap.release()\n",
    "        print(f\"{frame_count} fotogramas extraídos.\")\n",
    "    else:\n",
    "        print(\"No se encontraron videos. Creando 100 imágenes de demostración...\")\n",
    "        for i in range(100):\n",
    "            dummy_image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "            cv2.imwrite(os.path.join(frames_dir, f\"frame_{i:04d}.jpg\"), dummy_image)\n",
    "        frame_count = 100\n",
    "\n",
    "    # 3. Generar y simular el archivo de etiquetas\n",
    "    frame_files = sorted([f for f in os.listdir(frames_dir) if f.endswith('.jpg')])\n",
    "    if not frame_files:\n",
    "        raise ValueError(\"No se generaron fotogramas. No se puede continuar.\")\n",
    "    \n",
    "    df = pd.DataFrame({'frame': frame_files})\n",
    "    # Simular etiquetado aleatorio para que el split funcione\n",
    "    df['has_bicycle'] = np.random.randint(0, 2, df.shape[0])\n",
    "    df.to_csv(labels_csv, index=False)\n",
    "    print(f\"Archivo '{labels_csv}' generado y simulado con {len(df)} etiquetas aleatorias.\")\n",
    "\n",
    "# Ejecutar la preparación de datos automatizada\n",
    "setup_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cargar y Preprocesar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "labels_df = pd.read_csv('../data/labels.csv')\n",
    "labels_df['has_bicycle'] = labels_df['has_bicycle'].astype(str)\n",
    "\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42, stratify=labels_df['has_bicycle'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/frames',\n",
    "    x_col='frame',\n",
    "    y_col='has_bicycle',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory='../data/frames',\n",
    "    x_col='frame',\n",
    "    y_col='has_bicycle',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construcción y Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo (si hay datos)\n",
    "if train_generator.n > 0 and validation_generator.n > 0:\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
    "        epochs=10, # En un caso real, usar más épocas\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.n // BATCH_SIZE\n",
    "    )\n",
    "else:\n",
    "    print(\"No hay suficientes datos para entrenar. Por favor, verifica tus datos y etiquetas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Guardar el Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../bicycle_detection_model.h5')\n",
    "print(\"Modelo guardado como '../bicycle_detection_model.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
